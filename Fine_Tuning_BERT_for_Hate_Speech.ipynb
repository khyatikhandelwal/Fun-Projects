{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P02sV4GxcaKj"
      },
      "outputs": [],
      "source": [
        "# Load relevant packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import csv\n",
        "import operator\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import defaultdict, Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lds6K_5rTFTn"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"founta2018_formative2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "SxjPIYtVcYal",
        "outputId": "b8918b0e-cd53-41e1-bb61-867c8b513d07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   tweet   label\n",
              "42083  MK Dons Boss Robbie Neilson Hails Leicester Yo...  normal\n",
              "72731  EXO's Sehun shares future plans for upcoming s...  normal\n",
              "71150  What if I've recharged my number with 303 on 2...  normal\n",
              "50169  Nice Move-in ready House with great views in w...    spam\n",
              "36734  I wish I was an ear. They literally need to ea...  normal"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5165e09-3cfe-4015-bb9a-d23fc7cf011d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42083</th>\n",
              "      <td>MK Dons Boss Robbie Neilson Hails Leicester Yo...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72731</th>\n",
              "      <td>EXO's Sehun shares future plans for upcoming s...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71150</th>\n",
              "      <td>What if I've recharged my number with 303 on 2...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50169</th>\n",
              "      <td>Nice Move-in ready House with great views in w...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36734</th>\n",
              "      <td>I wish I was an ear. They literally need to ea...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5165e09-3cfe-4015-bb9a-d23fc7cf011d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5165e09-3cfe-4015-bb9a-d23fc7cf011d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5165e09-3cfe-4015-bb9a-d23fc7cf011d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "df.sample(5, random_state = 123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAt1bWzMcja1"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "\n",
        "    #replace mentions and URLs with special token\n",
        "       text = re.sub(r\"@[A-Za-z0-9_-]+\",'USR',text)\n",
        "       text = re.sub(r\"http\\S+\",'URL',text)\n",
        "    \n",
        "    # remove newline and tab characters\n",
        "       text = text.replace('\\n',' ')\n",
        "       text = text.replace('\\t',' ')\n",
        "       text = text.replace('rt', ' ')\n",
        "\n",
        "       text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "    \n",
        "    # strip whitespace\n",
        "       text = text.strip()\n",
        "    \n",
        "    # lowercase\n",
        "       text = text.lower()\n",
        "    \n",
        "       return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyNBSG0UmUHB"
      },
      "outputs": [],
      "source": [
        "# Clean tweets\n",
        "df[\"tweet\"] = df.tweet.apply(lambda x: clean_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_z8HrVZcwYR",
        "outputId": "652b5e7d-b10a-43b0-db52-96a247cc4a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99996 posts, of which 12710 were dropped for being duplicates.\n",
            "87286 posts remain. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def drop_dupl(df):\n",
        "\n",
        "    # save number of documents before dropping duplicates\n",
        "    n_docs = df.shape[0]\n",
        "\n",
        "    # drop duplicates\n",
        "    df.drop_duplicates(subset = ['tweet'], inplace=True)\n",
        "\n",
        "    print(f'{n_docs} posts, of which {n_docs - df.shape[0]} were dropped for being duplicates.')\n",
        "    print(f'{df.shape[0]} posts remain. \\n')\n",
        "    \n",
        "    return df\n",
        "\n",
        "df = drop_dupl(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPuTkBgDd-j7"
      },
      "outputs": [],
      "source": [
        "with open('FastTextDictionary.pickle', 'rb') as handle:\n",
        "    FastText = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdBT6EaAm_AO"
      },
      "outputs": [],
      "source": [
        "def lis(text):\n",
        "  return text.split(' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1XyCKt2nwPb"
      },
      "outputs": [],
      "source": [
        "df['cleaned'] = df.tweet.apply(lis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fDUkh92MoO7G",
        "outputId": "613af361-9b6a-4c9f-ccd2-9f6d6a6bc8cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               tweet        label  \\\n",
              "1  rt usr: man it would fucking rule if we had a ...  non-hateful   \n",
              "2  it is time to draw close to him   father, i dr...  non-hateful   \n",
              "3  if you notice me sta  to act different or dist...  non-hateful   \n",
              "4  forget unfollowers, i believe in growing. 7 ne...  non-hateful   \n",
              "5  rt usr: hate being sexually frustrated like i ...  non-hateful   \n",
              "\n",
              "                                             cleaned  \n",
              "1  [rt, usr:, man, it, would, fucking, rule, if, ...  \n",
              "2  [it, is, time, to, draw, close, to, him, , , f...  \n",
              "3  [if, you, notice, me, sta, , to, act, differen...  \n",
              "4  [forget, unfollowers,, i, believe, in, growing...  \n",
              "5  [rt, usr:, hate, being, sexually, frustrated, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bacf3d4-9069-4292-9371-ee579e29378d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rt usr: man it would fucking rule if we had a ...</td>\n",
              "      <td>non-hateful</td>\n",
              "      <td>[rt, usr:, man, it, would, fucking, rule, if, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it is time to draw close to him   father, i dr...</td>\n",
              "      <td>non-hateful</td>\n",
              "      <td>[it, is, time, to, draw, close, to, him, , , f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>if you notice me sta  to act different or dist...</td>\n",
              "      <td>non-hateful</td>\n",
              "      <td>[if, you, notice, me, sta, , to, act, differen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>forget unfollowers, i believe in growing. 7 ne...</td>\n",
              "      <td>non-hateful</td>\n",
              "      <td>[forget, unfollowers,, i, believe, in, growing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>rt usr: hate being sexually frustrated like i ...</td>\n",
              "      <td>non-hateful</td>\n",
              "      <td>[rt, usr:, hate, being, sexually, frustrated, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bacf3d4-9069-4292-9371-ee579e29378d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bacf3d4-9069-4292-9371-ee579e29378d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bacf3d4-9069-4292-9371-ee579e29378d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8V1lr33AruJk"
      },
      "outputs": [],
      "source": [
        "# Split data into training, development, and test sets\n",
        "train, dev_test = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=0)\n",
        "dev, test = train_test_split(dev_test, test_size=0.5, stratify=dev_test['label'], random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjnpfjaqsVYd",
        "outputId": "9f8ece2f-f6d7-4a76-94e3-3e25860a55c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9tBTN_GsPEv"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import warnings\n",
        "\n",
        "from collections import defaultdict, Counter\n",
        "from string import punctuation\n",
        "from matplotlib import pyplot as plt\n",
        "from nltk.util import bigrams\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.feature_extraction import _stop_words\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MT9kn77UsA8F"
      },
      "outputs": [],
      "source": [
        "# Define dataset class\n",
        "class BERTDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data):\n",
        "        \n",
        "        # Initialize tokenizer\n",
        "        self.tok = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        \n",
        "        # Truncate and encode abstracts\n",
        "        self.tweets = (data.cleaned.apply(self.tok.encode, max_length=50, truncation=True))\n",
        "        \n",
        "        # Store labels\n",
        "        self.labels = list(data.label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tweet = self.tweets[idx]\n",
        "        label = self.labels[idx]\n",
        "        return tweet, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfDmYdZ3sf3e"
      },
      "outputs": [],
      "source": [
        "def bert_collate(batch):\n",
        "    # Store batch size\n",
        "    batch_size = len(batch)\n",
        "    \n",
        "    # Separate tweets and labels\n",
        "    tweets = [t for t, l in batch]\n",
        "    labels = [l for t, l in batch]\n",
        "    \n",
        "    # Check that all labels are valid\n",
        "    valid_labels = {\"hateful\", \"normal\", \"abusive\", \"spam\"}\n",
        "    if not set(labels).issubset(valid_labels):\n",
        "        raise ValueError(\"Invalid label found in batch: {}\".format(labels))\n",
        "    \n",
        "    # Convert labels to integers\n",
        "    label2id = {\"hateful\": 0, \"normal\": 1, \"abusive\" : 2, \"spam\": 3}\n",
        "    label_ids = torch.tensor([label2id[l] for l in labels]).long()\n",
        "    \n",
        "    # Store length of longest tweet in batch\n",
        "    max_len = max(len(t) for t in tweets)\n",
        "    \n",
        "    # Create padded tweet and attention mask tensors\n",
        "    tweets_pad = torch.zeros((batch_size, max_len)).long()\n",
        "    masks_pad = torch.zeros((batch_size, max_len)).long()\n",
        "    for i, t in enumerate(tweets):\n",
        "        tweets_pad[i, :len(t)] = torch.tensor(t)\n",
        "        masks_pad[i, :len(t)] = 1\n",
        "    \n",
        "    return tweets_pad, masks_pad, label_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzZmO21nslND"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Create the BertClassifier class\n",
        "\n",
        "class BertClassifier_RELU(nn.Module):\n",
        "    \n",
        "    def __init__(self, freeze_bert=False):\n",
        "        super(BertClassifier,self).__init__()\n",
        "        \n",
        "        # Specify hidden size of Bert, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50 , 4\n",
        "        \n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "                            nn.Linear(D_in, H),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Linear(H, D_out))\n",
        "        \n",
        "        # Freeze the Bert Model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "    \n",
        "    def forward(self,input_ids,attention_mask, output_attentions=True):\n",
        "\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                           attention_mask = attention_mask, output_attentions=True)\n",
        "        \n",
        "        overall = outputs\n",
        "\n",
        "        attentions = outputs.attentions\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:,0,:]\n",
        "        \n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "        \n",
        "        return logits, overall, attentions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define BERT classifier\n",
        "class BERTClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        \n",
        "        # Define network layers\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.linear = nn.Linear(768, 4)\n",
        "        \n",
        "        # Define dropout\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "        # Freeze BERT layers\n",
        "        for n, p in self.bert.named_parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    def forward(self, tweets, masks, output_attentions=True):\n",
        "        \n",
        "        # Define flow of tensors through network\n",
        "        outputs = self.bert(tweets, attention_mask=masks, output_attentions = True)\n",
        "        attentions = outputs.attentions\n",
        "        output_bert = self.bert(tweets, attention_mask=masks)[0].mean(axis=1)\n",
        "        return self.linear(self.dropout(output_bert)), outputs, attentions"
      ],
      "metadata": {
        "id": "gPeGTxH5bxSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ca_1jmcNuXt"
      },
      "outputs": [],
      "source": [
        "train = train.reset_index()\n",
        "dev = dev.reset_index()\n",
        "test = test.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uM4oPaflsngP"
      },
      "outputs": [],
      "source": [
        "# Create datasets\n",
        "train_dataset = BERTDataset(train)\n",
        "dev_dataset = BERTDataset(dev)\n",
        "test_dataset = BERTDataset(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9uVIdYvs9ik"
      },
      "outputs": [],
      "source": [
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=100, collate_fn=bert_collate, shuffle=True)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=100, collate_fn=bert_collate)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100, collate_fn=bert_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cmluLJ6tPuj",
        "outputId": "fbe5ef0c-c249-49b0-ff80-3e4d744d4313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Initialize model\n",
        "model = BERTClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sadice"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh8zGxLTpUzD",
        "outputId": "bc9f4936-bd01-4415-8d09-e2b2b25bc3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sadice\n",
            "  Downloading sadice-0.1.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: torch<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from sadice) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch<2.0.0,>=1.0.0->sadice) (4.5.0)\n",
            "Installing collected packages: sadice\n",
            "Successfully installed sadice-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sadice import SelfAdjDiceLoss\n",
        "\n",
        "criterion = SelfAdjDiceLoss()"
      ],
      "metadata": {
        "id": "vmTrnHXTccZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class F1Loss(nn.Module):\n",
        "    def __init__(self, eps=1e-7):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        tp = (y_pred * y_true).sum(dim=0)\n",
        "        fp = (y_pred * (1 - y_true)).sum(dim=0)\n",
        "        fn = ((1 - y_pred) * y_true).sum(dim=0)\n",
        "\n",
        "        precision = tp / (tp + fp + self.eps)\n",
        "        recall = tp / (tp + fn + self.eps)\n",
        "        f1 = 2 * (precision * recall) / (precision + recall + self.eps)\n",
        "\n",
        "        return 1 - f1.mean()"
      ],
      "metadata": {
        "id": "m7H-1O6X128w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class WeightedCrossEntropyLoss(nn.Module):\n",
        "    def __init__(self, weights=None):\n",
        "        super().__init__()\n",
        "        self.weights = weights\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        log_probs = nn.functional.log_softmax(input, dim=1)\n",
        "        loss = nn.functional.nll_loss(log_probs, target, weight=self.weights)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "vC481yaF3sCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXMlqTM-tR2L"
      },
      "outputs": [],
      "source": [
        "# Define optimizer and training objective\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ5gS-O1_E58",
        "outputId": "d9301215-cd81-4060-f2a0-fa09aad4a19b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88\n"
          ]
        }
      ],
      "source": [
        "print(len(dev_loader))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "HyX17U4GpHB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQUbhjwStYof",
        "outputId": "3511e4ef-a478-471e-e391-b66a4f667185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 699/699 [24:01<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished epoch 1\n",
            "Accuracy after 1 epoch(s): 0.74\n",
            "[[  58  263   79    7]\n",
            " [  20 4568   60  410]\n",
            " [ 108  530 1322   53]\n",
            " [   0  656   50  545]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.14      0.20       407\n",
            "           1       0.76      0.90      0.82      5058\n",
            "           2       0.87      0.66      0.75      2013\n",
            "           3       0.54      0.44      0.48      1251\n",
            "\n",
            "    accuracy                           0.74      8729\n",
            "   macro avg       0.62      0.53      0.56      8729\n",
            "weighted avg       0.73      0.74      0.73      8729\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 699/699 [23:55<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished epoch 2\n",
            "Accuracy after 2 epoch(s): 0.76\n",
            "[[  24  155  222    6]\n",
            " [  19 4251  302  486]\n",
            " [  10  187 1790   26]\n",
            " [   0  601   80  570]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.06      0.10       407\n",
            "           1       0.82      0.84      0.83      5058\n",
            "           2       0.75      0.89      0.81      2013\n",
            "           3       0.52      0.46      0.49      1251\n",
            "\n",
            "    accuracy                           0.76      8729\n",
            "   macro avg       0.64      0.56      0.56      8729\n",
            "weighted avg       0.74      0.76      0.74      8729\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 699/699 [24:00<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished epoch 3\n",
            "Accuracy after 3 epoch(s): 0.77\n",
            "[[   7  224  174    2]\n",
            " [   5 4797  161   95]\n",
            " [   5  330 1672    6]\n",
            " [   0  982   62  207]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.02      0.03       407\n",
            "           1       0.76      0.95      0.84      5058\n",
            "           2       0.81      0.83      0.82      2013\n",
            "           3       0.67      0.17      0.27      1251\n",
            "\n",
            "    accuracy                           0.77      8729\n",
            "   macro avg       0.66      0.49      0.49      8729\n",
            "weighted avg       0.74      0.77      0.72      8729\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 699/699 [23:52<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished epoch 4\n",
            "Accuracy after 4 epoch(s): 0.76\n",
            "[[  21  246  138    2]\n",
            " [   8 4824   99  127]\n",
            " [  23  422 1556   12]\n",
            " [   0  941   56  254]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.05      0.09       407\n",
            "           1       0.75      0.95      0.84      5058\n",
            "           2       0.84      0.77      0.81      2013\n",
            "           3       0.64      0.20      0.31      1251\n",
            "\n",
            "    accuracy                           0.76      8729\n",
            "   macro avg       0.66      0.50      0.51      8729\n",
            "weighted avg       0.74      0.76      0.72      8729\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "for e in range(4):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i, b in enumerate(tqdm(train_loader)):\n",
        "\n",
        "        # Perform forward pass\n",
        "        optimizer.zero_grad()\n",
        "        tweets, masks, lbls = [t for t in b]\n",
        "        output,overall,attn = model(tweets, masks, output_attentions= True)\n",
        "        loss = criterion(output, lbls)\n",
        "        \n",
        "        # Perform backpropagation and update weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "  \n",
        "    # Evaluate model on development data\n",
        "    model.eval()\n",
        "\n",
        "    y_true = list()\n",
        "    y_pred = list()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for b in dev_loader:\n",
        "            tweets, masks, lbls = [t for t in b]\n",
        "            output,overall,attn = model(tweets, masks)\n",
        "            max_output = output.argmax(dim=1)\n",
        "            y_true.extend(lbls.tolist())\n",
        "            y_pred.extend(max_output.tolist())\n",
        "\n",
        "    print(\"Finished epoch\", e+1)\n",
        "\n",
        "    print('Accuracy after {} epoch(s): {:.2f}'.format(e+1, accuracy_score(y_true, y_pred)))\n",
        "    print(confusion_matrix(y_true,y_pred))\n",
        "    print(classification_report(y_true,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaM6UO2PfLB0"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'bert_finding_attention_50len.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flxcbVJbcTNb"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Instantiate tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XM8Yo2ucFze"
      },
      "outputs": [],
      "source": [
        "def display_sentence_attention(model, tokenizer, sentence):\n",
        "    model.eval()\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    tensor_tokens = torch.tensor([indexed_tokens])\n",
        "\n",
        "    # Create attention masks\n",
        "    attention_mask = [1] * len(tokens)\n",
        "\n",
        "    # Convert inputs to PyTorch tensors\n",
        "    tensor_mask = torch.tensor([attention_mask])\n",
        "\n",
        "    # Predict label and get attention scores\n",
        "    with torch.no_grad():\n",
        "        #outputs, attn_scores = model(tensor_tokens, tensor_mask, return_dict=False, output_attentions=True)\n",
        "        outputs, all, attn_scores = model(tensor_tokens, tensor_mask, output_attentions=True)\n",
        "        pred_label = torch.argmax(outputs).item()\n",
        "\n",
        "    # Decode attention scores and display highlighted sentence\n",
        "    attn_scores = _decode_output({'attentions': attn_scores})\n",
        "    display(HTML(f'<strong>Predicted Label:</strong> {pred_label}'))\n",
        "    for layer in range(len(attn_scores['aa']['attn'])):\n",
        "        for head in range(len(attn_scores['aa']['attn'][layer])):\n",
        "            display(HTML(f'<strong>Layer {layer+1} Head {head+1}:</strong>'))\n",
        "            disp_attn_tokens(tokens, attn_scores['aa']['attn'], layer, head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIKDZZR_VOjR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.core.display import HTML\n",
        "import html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfjTrcIna3O1"
      },
      "outputs": [],
      "source": [
        "import html\n",
        "\n",
        "def display_attention(tokens, attn_matrix, layer=-1, head=0, direction='ba'):\n",
        "    token_weights = attn_matrix[layer][head].detach().cpu().numpy()\n",
        "    tokens = [t for t in tokens if t != tokenizer.pad_token]\n",
        "    attention_weights = token_weights[direction == 'ba'][0]\n",
        "    highlighted_text = []\n",
        "    for i, (token, weight) in enumerate(zip(tokens, attention_weights)):\n",
        "        if weight != 0:\n",
        "            # Calculate the background color for the current token based on its attention weight\n",
        "            color = f'rgba(255,0,0,{weight:.8f})'\n",
        "            # If this isn't the first token in the sentence, calculate the color for the previous token as well\n",
        "            if i > 0:\n",
        "                prev_weight = attention_weights[i-1]\n",
        "                if prev_weight != 0:\n",
        "                    prev_color = f'rgba(255,0,0,{prev_weight:.8f})'\n",
        "                else:\n",
        "                    prev_color = 'white'\n",
        "            else:\n",
        "                prev_color = 'white'\n",
        "            # Add the current token to the highlighted text string with a gradient background color\n",
        "            highlighted_text.append(f'<span style=\"background: linear-gradient(to right, {prev_color}, {color})\">{html.escape(str(token))}</span>')\n",
        "        else:\n",
        "            highlighted_text.append(str(token))\n",
        "    highlighted_text = ' '.join(highlighted_text)\n",
        "    display(HTML(highlighted_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCGX5J88b6-q"
      },
      "outputs": [],
      "source": [
        "def display_attention_2(tokens, attn_matrix, layer=-1, head=0, direction='ba'):\n",
        "    token_weights = attn_matrix[layer][head].detach().cpu().numpy()\n",
        "    attention_weights = token_weights[direction == 'ba'][0][:len(tokens)]\n",
        "    tokens = [t for t in tokens if t != tokenizer.pad_token]\n",
        "    highlighted_text = []\n",
        "    for i, (token, weight) in enumerate(zip(tokens, attention_weights)):\n",
        "        color = f'rgba(255,0,0,{weight:.2f})'\n",
        "        highlighted_text.append(f'<span style=\"background-color: {color}\">{html.escape(token)}</span>')\n",
        "    highlighted_text = ' '.join(highlighted_text)\n",
        "    display(HTML(highlighted_text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "k9O6VX-0VTXz",
        "outputId": "7ffe0575-d4a0-4b11-ee3e-2cf419516366"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span style=\"background: linear-gradient(to right, white, rgba(255,100,100,0.00376967))\">[CLS]</span> <span style=\"background: linear-gradient(to right, rgba(255,100,100,0.00376967), rgba(255,100,100,0.01153744))\">if</span> <span style=\"background: linear-gradient(to right, rgba(255,100,100,0.01153744), rgba(255,100,100,0.00357115))\">you&#x27;re</span> <span style=\"background: linear-gradient(to right, rgba(255,100,100,0.00357115), rgba(255,100,100,0.49035209))\">a</span> <span style=\"background: linear-gradient(to right, rgba(255,100,100,0.49035209), rgba(255,100,100,0.00922917))\">black</span> <span style=\"background: linear-gradient(to right, rgba(255,100,100,0.00922917), rgba(255,100,100,0.01693956))\">person,</span> <span style=\"background: linear-gradient(to right, rgba(255,100,100,0.01693956), rgba(255,100,100,0.01100610))\">kill</span> <span style=\"background: linear-gradient(to right, rgba(255,100,100,0.01100610), rgba(255,100,100,0.00734088))\">yourself!!!!</span> <span style=\"background: linear-gradient(to right, rgba(255,100,100,0.00734088), rgba(255,100,100,0.00383532))\">url</span> <span style=\"background: linear-gradient(to right, rgba(255,100,100,0.00383532), rgba(255,100,100,0.00826935))\">[SEP]</span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "input_text = \"If you're a black person, kill yourself!!!! url\"\n",
        "tokens = tokenizer.encode_plus(input_text, max_length=128, truncation=True, padding='max_length', return_tensors='pt')\n",
        "\n",
        "# Get BERT model predictions and attentions\n",
        "predictions, outputs, attentions = model(tokens['input_ids'], tokens['attention_mask'])\n",
        "\n",
        "\n",
        "# Reshape attention tensor\n",
        "n_heads = attentions[11].shape[1]\n",
        "attn_matrix = attentions[-1].reshape(n_heads, tokens['input_ids'].shape[1], tokens['input_ids'].shape[1])\n",
        "\n",
        "decoded_tokens = tokenizer.decode(tokens['input_ids'][0])\n",
        "decoded_tokens = decoded_tokens.split(' ')\n",
        "\n",
        "display_attention(decoded_tokens, attn_matrix, layer= 1, head=11)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz7cuAB4eK4p",
        "outputId": "1dd300c4-232a-4377-89dd-e496075895a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64557    the improve troupe changed the names of all th...\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "df['tweet'][df['label']==\"hateful\"].sample(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrhxV2KAeunq",
        "outputId": "3bc3a577-00f2-4b77-835f-7a0147baa6f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.77\n",
            "[[  18  243  144    2]\n",
            " [   9 4815  108  126]\n",
            " [  20  407 1577   10]\n",
            " [   0  922   49  279]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.04      0.08       407\n",
            "           1       0.75      0.95      0.84      5058\n",
            "           2       0.84      0.78      0.81      2014\n",
            "           3       0.67      0.22      0.33      1250\n",
            "\n",
            "    accuracy                           0.77      8729\n",
            "   macro avg       0.66      0.50      0.52      8729\n",
            "weighted avg       0.74      0.77      0.73      8729\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "model.eval()\n",
        "\n",
        "y_true = list()\n",
        "y_pred = list()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for b in test_loader:\n",
        "        tweets, masks, lbls = [t for t in b]\n",
        "        output, overall, attn = model(tweets, masks)\n",
        "        max_output = output.argmax(dim=1)\n",
        "        y_true.extend(lbls.tolist())\n",
        "        y_pred.extend(max_output.tolist())\n",
        "\n",
        "print('Test accuracy: {:.2f}'.format(accuracy_score(y_true, y_pred)))\n",
        "print(confusion_matrix(y_true,y_pred))\n",
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e24mLyP6h1QA"
      },
      "outputs": [],
      "source": [
        "schema = {0:\"hateful\",1:\"normal\", 2:\"abusive\", 3:\"spam\"}\n",
        "test['pred'] = [schema[i] for i in y_pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "4EfjF1v3jAin",
        "outputId": "d00c6a5c-f1df-4c3c-93fd-6f3a1e4e6ddc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     level_0  index                                              tweet  \\\n",
              "184     4209  22183  usr usr too bad he's a xenophobic idiot with t...   \n",
              "249     5258  73986  rt usr: i'm embarrassed for those that voted f...   \n",
              "312     6531  27101  professor: republicans criticize susan rice be...   \n",
              "218     4769  78749         rt usr: you know niggas hate water smh url   \n",
              "93      2114  83496  usr usr he is rubbish, a subhuman idiot ! him ...   \n",
              "\n",
              "       label                                            cleaned     pred  \n",
              "184  hateful  [usr, usr, too, bad, he's, a, xenophobic, idio...  hateful  \n",
              "249  hateful  [rt, usr:, i'm, embarrassed, for, those, that,...  hateful  \n",
              "312  hateful  [professor:, republicans, criticize, susan, ri...  hateful  \n",
              "218  hateful  [rt, usr:, you, know, niggas, hate, water, smh...  hateful  \n",
              "93   hateful  [usr, usr, he, is, rubbish,, a, subhuman, idio...  hateful  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df62b537-56ec-45ea-be43-c07bd018b970\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>4209</td>\n",
              "      <td>22183</td>\n",
              "      <td>usr usr too bad he's a xenophobic idiot with t...</td>\n",
              "      <td>hateful</td>\n",
              "      <td>[usr, usr, too, bad, he's, a, xenophobic, idio...</td>\n",
              "      <td>hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>5258</td>\n",
              "      <td>73986</td>\n",
              "      <td>rt usr: i'm embarrassed for those that voted f...</td>\n",
              "      <td>hateful</td>\n",
              "      <td>[rt, usr:, i'm, embarrassed, for, those, that,...</td>\n",
              "      <td>hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>6531</td>\n",
              "      <td>27101</td>\n",
              "      <td>professor: republicans criticize susan rice be...</td>\n",
              "      <td>hateful</td>\n",
              "      <td>[professor:, republicans, criticize, susan, ri...</td>\n",
              "      <td>hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>4769</td>\n",
              "      <td>78749</td>\n",
              "      <td>rt usr: you know niggas hate water smh url</td>\n",
              "      <td>hateful</td>\n",
              "      <td>[rt, usr:, you, know, niggas, hate, water, smh...</td>\n",
              "      <td>hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>2114</td>\n",
              "      <td>83496</td>\n",
              "      <td>usr usr he is rubbish, a subhuman idiot ! him ...</td>\n",
              "      <td>hateful</td>\n",
              "      <td>[usr, usr, he, is, rubbish,, a, subhuman, idio...</td>\n",
              "      <td>hateful</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df62b537-56ec-45ea-be43-c07bd018b970')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df62b537-56ec-45ea-be43-c07bd018b970 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df62b537-56ec-45ea-be43-c07bd018b970');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ],
      "source": [
        "check = test[test['label']==\"hateful\"]\n",
        "check = check.reset_index()\n",
        "check[check[\"pred\"]==\"hateful\"].sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "sukIdV3tjG3u",
        "outputId": "2ffc2719-e54d-43fa-c44c-8db2303822ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"usr usr too bad he's a xenophobic idiot with the reading level of a 3rd grader with racist parents\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 199
        }
      ],
      "source": [
        "check['tweet'].iloc[184]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[train['label']==\"hateful\"].sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "hBdVe4jW6cWL",
        "outputId": "9e4f4276-11e1-4be1-9c16-6340aa30e1ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       index                                              tweet    label  \\\n",
              "64845  43829  don't hate you because niggas can't appreciate...  hateful   \n",
              "10558  72500  usr usr usr plenty of rats and rabbits are kil...  hateful   \n",
              "8387   27095                          rt usr: nigga u crazy url  hateful   \n",
              "18479  79835  i question whether or not the filthy casuals w...  hateful   \n",
              "36941  96195  anybody that does not obey the teachings of th...  hateful   \n",
              "\n",
              "                                                 cleaned  \n",
              "64845  [don't, hate, you, because, niggas, can't, app...  \n",
              "10558  [usr, usr, usr, plenty, of, rats, and, rabbits...  \n",
              "8387                    [rt, usr:, nigga, u, crazy, url]  \n",
              "18479  [i, question, whether, or, not, the, filthy, c...  \n",
              "36941  [anybody, that, does, not, obey, the, teaching...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82f326a5-6e0f-4ad2-adb3-c74234f734fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64845</th>\n",
              "      <td>43829</td>\n",
              "      <td>don't hate you because niggas can't appreciate...</td>\n",
              "      <td>hateful</td>\n",
              "      <td>[don't, hate, you, because, niggas, can't, app...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10558</th>\n",
              "      <td>72500</td>\n",
              "      <td>usr usr usr plenty of rats and rabbits are kil...</td>\n",
              "      <td>hateful</td>\n",
              "      <td>[usr, usr, usr, plenty, of, rats, and, rabbits...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8387</th>\n",
              "      <td>27095</td>\n",
              "      <td>rt usr: nigga u crazy url</td>\n",
              "      <td>hateful</td>\n",
              "      <td>[rt, usr:, nigga, u, crazy, url]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18479</th>\n",
              "      <td>79835</td>\n",
              "      <td>i question whether or not the filthy casuals w...</td>\n",
              "      <td>hateful</td>\n",
              "      <td>[i, question, whether, or, not, the, filthy, c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36941</th>\n",
              "      <td>96195</td>\n",
              "      <td>anybody that does not obey the teachings of th...</td>\n",
              "      <td>hateful</td>\n",
              "      <td>[anybody, that, does, not, obey, the, teaching...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82f326a5-6e0f-4ad2-adb3-c74234f734fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82f326a5-6e0f-4ad2-adb3-c74234f734fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82f326a5-6e0f-4ad2-adb3-c74234f734fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['tweet'].iloc[36941]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "Gw5eqsjBBIVF",
        "outputId": "34299c9a-8a71-4bab-903f-eba6ee3d5ab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'anybody that does not obey the teachings of the bible and jesus christ is a child of the devil a worker of iniquity url'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}