{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMH3-F7hkc2Z"
      },
      "source": [
        "# Formative 3: Particle Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "01wZbe0bkc2d"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import nltk\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict, Counter\n",
        "from html import unescape\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr-LI2D3kc2f",
        "outputId": "61fb6f39-c7a5-4e90-8c55-83c7c87d8cc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lDrwwlbQkc2g"
      },
      "outputs": [],
      "source": [
        "# Define function to clean and split text\n",
        "def clean(text):\n",
        "    text = unescape(text)\n",
        "    return [re.sub('[^a-z]', '', w.lower()) for w in text.strip().split()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "s50kONu6kc2g"
      },
      "outputs": [],
      "source": [
        "# Load dataframe\n",
        "df = pd.read_csv('formative3_data_us_equities_news.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "cdHadcDVTxdf",
        "outputId": "1ac54d4b-b9e3-40c7-c16b-135b2387a720"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0      id ticker  \\\n",
              "0                0  221515    NIO   \n",
              "1                1  221516    NIO   \n",
              "2                2  221517    NIO   \n",
              "3                3  221518    NIO   \n",
              "4                4  221519    NIO   \n",
              "...            ...     ...    ...   \n",
              "141243      142221  440043  CMCSA   \n",
              "141244      142222  440044  CMCSA   \n",
              "141245      142223  440045  CMCSA   \n",
              "141246      142224  440046   EBAY   \n",
              "141247      142225  440047   EBAY   \n",
              "\n",
              "                                                    title category  \\\n",
              "0       Why Shares of Chinese Electric Car Maker NIO A...     news   \n",
              "1       NIO only consumer gainer  Workhorse Group amon...     news   \n",
              "2       NIO leads consumer gainers  Beyond Meat and Ma...     news   \n",
              "3                       NIO  NVAX among premarket gainers     news   \n",
              "4                       PLUG  NIO among premarket gainers     news   \n",
              "...                                                   ...      ...   \n",
              "141243  Comcast Customer Data  Bundling is Dying  and ...     news   \n",
              "141244  AT T Ended 2019 With Fewer Video Subscribers T...     news   \n",
              "141245  Comcast  CMCSA  Beats Q4 Earnings And Revenue ...  opinion   \n",
              "141246                   3 Views To Bid On eBay At  45 50  opinion   \n",
              "141247        PayPal To  Launch  Space Payment Initiative  opinion   \n",
              "\n",
              "                                                  content release_date  \\\n",
              "0       What s happening\\nShares of Chinese electric c...   2020-01-15   \n",
              "1       Gainers  NIO  NYSE NIO   7  \\nLosers  MGP Ingr...   2020-01-18   \n",
              "2       Gainers  NIO  NYSE NIO   14   Village Farms In...   2020-01-15   \n",
              "3       Cemtrex  NASDAQ CETX   85  after FY results \\n...   2020-01-15   \n",
              "4       aTyr Pharma  NASDAQ LIFE   63  on Kyorin Pharm...   2020-01-06   \n",
              "...                                                   ...          ...   \n",
              "141243  The concept is simple enough  Customers of one...   2020-01-29   \n",
              "141244  AT T  NYSE T  lost another 1 16 million video ...   2020-01-30   \n",
              "141245  Comcast  CMCSA  came out with quarterly earnin...   2020-01-22   \n",
              "141246  The auction giant has long been discussed as h...   2013-06-04   \n",
              "141247  PayPal announced on Thursday that it was  laun...          NaN   \n",
              "\n",
              "                         provider  \\\n",
              "0                 The Motley Fool   \n",
              "1                   Seeking Alpha   \n",
              "2                   Seeking Alpha   \n",
              "3                   Seeking Alpha   \n",
              "4                   Seeking Alpha   \n",
              "...                           ...   \n",
              "141243            The Motley Fool   \n",
              "141244            The Motley Fool   \n",
              "141245  Zacks Investment Research   \n",
              "141246          Gregory W. Harmon   \n",
              "141247                        NaN   \n",
              "\n",
              "                                                      url   article_id  \n",
              "0                                  https://invst.ly/pigqi    2060327.0  \n",
              "1                                  https://invst.ly/pje9c    2062196.0  \n",
              "2                                  https://invst.ly/pifmv    2060249.0  \n",
              "3                                  https://invst.ly/picu8    2060039.0  \n",
              "4       https://seekingalpha.com/news/3529772-plug-nio...    2053096.0  \n",
              "...                                                   ...          ...  \n",
              "141243                             https://invst.ly/poet0    2070527.0  \n",
              "141244                             https://invst.ly/po-ev    2071864.0  \n",
              "141245  https://www.investing.com/analysis/comcast-cmc...  200500909.0  \n",
              "141246  https://www.investing.com/analysis/3-views-to-...     169867.0  \n",
              "141247                                                NaN          NaN  \n",
              "\n",
              "[141248 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c499f7a3-4551-4c25-ac29-4c01874a70ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>ticker</th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "      <th>content</th>\n",
              "      <th>release_date</th>\n",
              "      <th>provider</th>\n",
              "      <th>url</th>\n",
              "      <th>article_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>221515</td>\n",
              "      <td>NIO</td>\n",
              "      <td>Why Shares of Chinese Electric Car Maker NIO A...</td>\n",
              "      <td>news</td>\n",
              "      <td>What s happening\\nShares of Chinese electric c...</td>\n",
              "      <td>2020-01-15</td>\n",
              "      <td>The Motley Fool</td>\n",
              "      <td>https://invst.ly/pigqi</td>\n",
              "      <td>2060327.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>221516</td>\n",
              "      <td>NIO</td>\n",
              "      <td>NIO only consumer gainer  Workhorse Group amon...</td>\n",
              "      <td>news</td>\n",
              "      <td>Gainers  NIO  NYSE NIO   7  \\nLosers  MGP Ingr...</td>\n",
              "      <td>2020-01-18</td>\n",
              "      <td>Seeking Alpha</td>\n",
              "      <td>https://invst.ly/pje9c</td>\n",
              "      <td>2062196.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>221517</td>\n",
              "      <td>NIO</td>\n",
              "      <td>NIO leads consumer gainers  Beyond Meat and Ma...</td>\n",
              "      <td>news</td>\n",
              "      <td>Gainers  NIO  NYSE NIO   14   Village Farms In...</td>\n",
              "      <td>2020-01-15</td>\n",
              "      <td>Seeking Alpha</td>\n",
              "      <td>https://invst.ly/pifmv</td>\n",
              "      <td>2060249.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>221518</td>\n",
              "      <td>NIO</td>\n",
              "      <td>NIO  NVAX among premarket gainers</td>\n",
              "      <td>news</td>\n",
              "      <td>Cemtrex  NASDAQ CETX   85  after FY results \\n...</td>\n",
              "      <td>2020-01-15</td>\n",
              "      <td>Seeking Alpha</td>\n",
              "      <td>https://invst.ly/picu8</td>\n",
              "      <td>2060039.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>221519</td>\n",
              "      <td>NIO</td>\n",
              "      <td>PLUG  NIO among premarket gainers</td>\n",
              "      <td>news</td>\n",
              "      <td>aTyr Pharma  NASDAQ LIFE   63  on Kyorin Pharm...</td>\n",
              "      <td>2020-01-06</td>\n",
              "      <td>Seeking Alpha</td>\n",
              "      <td>https://seekingalpha.com/news/3529772-plug-nio...</td>\n",
              "      <td>2053096.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141243</th>\n",
              "      <td>142221</td>\n",
              "      <td>440043</td>\n",
              "      <td>CMCSA</td>\n",
              "      <td>Comcast Customer Data  Bundling is Dying  and ...</td>\n",
              "      <td>news</td>\n",
              "      <td>The concept is simple enough  Customers of one...</td>\n",
              "      <td>2020-01-29</td>\n",
              "      <td>The Motley Fool</td>\n",
              "      <td>https://invst.ly/poet0</td>\n",
              "      <td>2070527.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141244</th>\n",
              "      <td>142222</td>\n",
              "      <td>440044</td>\n",
              "      <td>CMCSA</td>\n",
              "      <td>AT T Ended 2019 With Fewer Video Subscribers T...</td>\n",
              "      <td>news</td>\n",
              "      <td>AT T  NYSE T  lost another 1 16 million video ...</td>\n",
              "      <td>2020-01-30</td>\n",
              "      <td>The Motley Fool</td>\n",
              "      <td>https://invst.ly/po-ev</td>\n",
              "      <td>2071864.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141245</th>\n",
              "      <td>142223</td>\n",
              "      <td>440045</td>\n",
              "      <td>CMCSA</td>\n",
              "      <td>Comcast  CMCSA  Beats Q4 Earnings And Revenue ...</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Comcast  CMCSA  came out with quarterly earnin...</td>\n",
              "      <td>2020-01-22</td>\n",
              "      <td>Zacks Investment Research</td>\n",
              "      <td>https://www.investing.com/analysis/comcast-cmc...</td>\n",
              "      <td>200500909.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141246</th>\n",
              "      <td>142224</td>\n",
              "      <td>440046</td>\n",
              "      <td>EBAY</td>\n",
              "      <td>3 Views To Bid On eBay At  45 50</td>\n",
              "      <td>opinion</td>\n",
              "      <td>The auction giant has long been discussed as h...</td>\n",
              "      <td>2013-06-04</td>\n",
              "      <td>Gregory W. Harmon</td>\n",
              "      <td>https://www.investing.com/analysis/3-views-to-...</td>\n",
              "      <td>169867.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141247</th>\n",
              "      <td>142225</td>\n",
              "      <td>440047</td>\n",
              "      <td>EBAY</td>\n",
              "      <td>PayPal To  Launch  Space Payment Initiative</td>\n",
              "      <td>opinion</td>\n",
              "      <td>PayPal announced on Thursday that it was  laun...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>141248 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c499f7a3-4551-4c25-ac29-4c01874a70ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c499f7a3-4551-4c25-ac29-4c01874a70ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c499f7a3-4551-4c25-ac29-4c01874a70ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OWmGfq8okc2h"
      },
      "outputs": [],
      "source": [
        "# Remove columns not needed for formative\n",
        "df = df[['content', 'provider']]\n",
        "df['content'] = df['content'].astype(str)\n",
        "\n",
        "# Remove empty comments\n",
        "df = df[df.content.apply(lambda x: len(clean(x))) > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAilF8wFkc2h",
        "outputId": "c47066e0-7186-4c02-c663-340f9b5d4455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 141248/141248 [02:22<00:00, 988.18it/s]\n"
          ]
        }
      ],
      "source": [
        "#Define a dictionnary for particle lookup ( from part. to part id)\n",
        "p2id = {'give': 0, 'buy': 1, 'hold': 2, 'sell': 3}\n",
        "\n",
        "# Define dictionary for reverse particle look-up (from id to part.)\n",
        "id2p = {v: k for k, v in p2id.items()}\n",
        "\n",
        "# Initialize lists for storing contexts around particles\n",
        "sent_1 = list()\n",
        "sent_2 = list()\n",
        "\n",
        "# Initialize list for storing labels\n",
        "labels = list()\n",
        "\n",
        "# Loop over comments\n",
        "for c in tqdm(df.content):\n",
        "    \n",
        "    # Loop over individual sentences\n",
        "    for s in nltk.sent_tokenize(c):\n",
        "        \n",
        "        # Clean and split sentence\n",
        "        split = clean(s)\n",
        "        \n",
        "        if len(split) < 10:\n",
        "            continue\n",
        "        \n",
        "        # Add sentence to list if only one particle in sentence\n",
        "        if len([w for w in split if w in p2id]) == 1:\n",
        "            \n",
        "            # Identify particle\n",
        "            p = [w for w in split if w in p2id][0]\n",
        "\n",
        "            # Store contexts and label\n",
        "            sent_1.append(split[:split.index(p)])\n",
        "            sent_2.append(split[split.index(p) + 1:])\n",
        "            labels.append(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ady_1j3akc2i"
      },
      "outputs": [],
      "source": [
        "# Create dataframe with contexts and labels and perform stratified sampling\n",
        "p_df = pd.DataFrame({'sent_1': sent_1, 'sent_2': sent_2, 'label': labels})[['sent_1', 'sent_2', 'label']]\n",
        "p_df = p_df.groupby('label', group_keys=False).apply(lambda x: x.sample(n=1500, random_state=123, replace = True)).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qFpT2B2dkc2i"
      },
      "outputs": [],
      "source": [
        "# Split dataframe into training, evaluation, and test data\n",
        "train, dev_test = train_test_split(p_df, test_size=0.2, stratify=p_df['label'], random_state=123)\n",
        "dev, test = train_test_split(dev_test, test_size=0.5, stratify=dev_test['label'], random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "tssclfIHxGp8",
        "outputId": "9324cd6c-9bf0-41f8-f602-c31b1fbbba17"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              sent_1  \\\n",
              "0  [a, , contraction, for, the, u, s, economy, du...   \n",
              "1  [getting, big, returns, from, financial, portf...   \n",
              "2  [kb, home, nyse, kbh, announced, the, addition...   \n",
              "3  [investors, interested, in, retail, discount, ...   \n",
              "4  [shares, of, broadridge, financial, solutions,...   \n",
              "\n",
              "                                              sent_2 label  \n",
              "0  [t, mobile, us, nyse, tmus, commodities, finis...   buy  \n",
              "1                                                 []   buy  \n",
              "2  [you, can, see, other, top, ranked, stocks, in...   buy  \n",
              "3  [right, now, this, system, places, an, emphasi...   buy  \n",
              "4  [another, favorably, placed, stock, in, the, o...   buy  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbbb33e3-7882-49df-9964-76cffb628dbd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent_1</th>\n",
              "      <th>sent_2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[a, , contraction, for, the, u, s, economy, du...</td>\n",
              "      <td>[t, mobile, us, nyse, tmus, commodities, finis...</td>\n",
              "      <td>buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[getting, big, returns, from, financial, portf...</td>\n",
              "      <td>[]</td>\n",
              "      <td>buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[kb, home, nyse, kbh, announced, the, addition...</td>\n",
              "      <td>[you, can, see, other, top, ranked, stocks, in...</td>\n",
              "      <td>buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[investors, interested, in, retail, discount, ...</td>\n",
              "      <td>[right, now, this, system, places, an, emphasi...</td>\n",
              "      <td>buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[shares, of, broadridge, financial, solutions,...</td>\n",
              "      <td>[another, favorably, placed, stock, in, the, o...</td>\n",
              "      <td>buy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbbb33e3-7882-49df-9964-76cffb628dbd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fbbb33e3-7882-49df-9964-76cffb628dbd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fbbb33e3-7882-49df-9964-76cffb628dbd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQfJffbekc2i",
        "outputId": "8ab15426-1bad-4445-94b6-5d00c126f0e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'consumer',\n",
              " 'staples',\n",
              " 'select',\n",
              " 'sector',\n",
              " 'spdr',\n",
              " 'nyse',\n",
              " 'xlp',\n",
              " 'is',\n",
              " 'an']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Hint : Create dictionary for word look-up, this is helpfull for the word encoding later\n",
        "sent = train.sent_1 + train.sent_2\n",
        "words = []\n",
        "for i in sent:\n",
        "  for j in i:\n",
        "    words.append(j)\n",
        "words[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_counter = Counter(words)\n",
        "del word_counter['']\n",
        "w2id = Counter() # words to indices mapper\n",
        "i = 2\n",
        "for key,val in word_counter.most_common(5000):\n",
        "    w2id[key] = i\n",
        "    i +=1\n",
        "# Create dictionary for reverse word look-up\n",
        "id2w = Counter() # don't forget about reverse mapping ( otherwise you don't know how to translate back from encoded representations)"
      ],
      "metadata": {
        "id": "esg31z4yI91p"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key,val in w2id.items():\n",
        "  id2w[val] = key"
      ],
      "metadata": {
        "id": "c_SAFs5hMroU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CICj1XCCkc2j"
      },
      "outputs": [],
      "source": [
        "# Define function to encode sentences\n",
        "def encode(sen, w2id):\n",
        "  output = []# encoder should take sentences and output the word to index representation\n",
        "  for word in sen:\n",
        "    if word in w2id.keys():\n",
        "      output.append(w2id[word])\n",
        "    else:\n",
        "      output.append(1)\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(w2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSaVezhfTHa-",
        "outputId": "3f551b19-a2da-43f2-90e0-072d3d42b7a6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "m02SnCXGkc2j"
      },
      "outputs": [],
      "source": [
        "# Padding & cutting stage\n",
        "# once you have your encoded sentences, you need to make lengths uniform\n",
        "# ie. a sentence like [12,13,5,6,8,9,17] should be lenght 5 and you need to cut it\n",
        "# ie. a sentence like [12,13,5] should be lenght 5 and you need to pad it with 0\n",
        "def pad(sent):\n",
        "    if len(sent) > 5:\n",
        "        while len(sent) > 5:\n",
        "          sent.pop()\n",
        "        \n",
        "    elif len(sent) < 5:\n",
        "        while len(sent) < 5:\n",
        "          sent.append(0)\n",
        "    return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VMGTRICNkc2j"
      },
      "outputs": [],
      "source": [
        "# Helper code \n",
        "# Encode and pad sentences\n",
        "for data in [train, dev, test]:\n",
        "    \n",
        "    # Encode and pad left contexts\n",
        "    data['enc_1'] = data.sent_1.apply(lambda x: pad(encode(x, w2id)))\n",
        "    \n",
        "    # Reverse order of right contexts prior to padding\n",
        "    data['enc_2'] = data.sent_2.apply(lambda x: pad(encode(x, w2id)[::-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASV5QXVrkc2k",
        "outputId": "0eeb1760-a078-474a-85e2-6e639408e228"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sell    1200\n",
              "buy     1200\n",
              "give    1200\n",
              "hold    1200\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Inspect dataframe to get a sense of the data\n",
        "train.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lam(i):\n",
        "    lis = [0] * 5000\n",
        "    for j in i:\n",
        "        if int(j) != 0:\n",
        "            lis[int(j)] += 1\n",
        "    return lis"
      ],
      "metadata": {
        "id": "DiB7Hdkto3UX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['combined'] = train['enc_1'] + train['enc_2']"
      ],
      "metadata": {
        "id": "xihrXE2r3dOP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['combined_lstm'] = train['enc_1_lstm'] + train['enc_2_lstm']"
      ],
      "metadata": {
        "id": "Rxsg1NwOcyfv"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['to_tensor'] = train['combined'].apply(lambda x: lam(x))"
      ],
      "metadata": {
        "id": "Ve3-g34E3Uqz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr_X = np.array(train.to_tensor.to_list())\n",
        "ten_X = torch.from_numpy(arr_X)"
      ],
      "metadata": {
        "id": "nZRNTZmU3Um6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr_X_lstm_right = np.array(train.enc_2_lstm.to_list())\n",
        "arr_X_lstm_left = np.array(train.enc_1_lstm.to_list())\n",
        "ten_X_lstm_right = torch.from_numpy(arr_X_lstm_right)\n",
        "tex_X_lstm_left = torch.from_numpy(arr_X_lstm_left)"
      ],
      "metadata": {
        "id": "Ud2v4JHpdKpI"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.get_dummies(train,prefix=['label'], columns = ['label'])"
      ],
      "metadata": {
        "id": "wsJ8VqLo6pYc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_arr_1 = train[['label_buy','label_sell','label_give','label_hold']].values"
      ],
      "metadata": {
        "id": "En9bYDFH9nGU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ten_y = torch.from_numpy(Y_arr_1)"
      ],
      "metadata": {
        "id": "yz4Sp1pC9yVD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.get_dummies(test,prefix=['label'], columns = ['label'])"
      ],
      "metadata": {
        "id": "ivxzlkF8Amaa"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_arr_2 = test[['label_buy','label_sell','label_give','label_hold']].values\n",
        "test_y =torch.from_numpy(Y_arr_2)"
      ],
      "metadata": {
        "id": "HgpqtS8dArvU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDg5qujDkc2k"
      },
      "source": [
        "### Part II: Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.classification import Accuracy"
      ],
      "metadata": {
        "id": "ZZvrRwaxZsUo"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "fc6mVRrjkc2k"
      },
      "outputs": [],
      "source": [
        "# Define logistic regression classifier class\n",
        "class LRClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        # don't forget the super layer\n",
        "        super(LRClassifier, self).__init__()\n",
        "        # create a Linear layer\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "    def forward(self,ten_X= ten_X):\n",
        "        outputs = torch.sigmoid(self.linear(ten_X))\n",
        "        return outputs\n",
        "    # create and fill a forward function as well "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ten_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXGOOKMsdgv0",
        "outputId": "8d78b9c1-b0f4-46a5-b123-d2c4d4709919"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4800, 5000])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = LRClassifier(5000,4)"
      ],
      "metadata": {
        "id": "YfD5AXh6gDp-"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X,y,steps = 20):\n",
        "    model = log_reg\n",
        "    # Define optimization method\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    # Define training objective\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    \n",
        "    model()\n",
        "\n",
        "    # Set all tensor gradients to zero\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    for step in range(steps):\n",
        "\n",
        "        # Perform forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(y_pred, y)\n",
        "\n",
        "        # Compute gradient of loss with respect to all model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Perform parameter update\n",
        "        optimizer.step()\n",
        "        \n",
        "        if step %5==0:\n",
        "\n",
        "            # Put neural net into evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # Specify that gradients should not be computed during evaluation\n",
        "            with torch.no_grad():\n",
        "                y_pred = model(X)    \n",
        "\n",
        "            y_pred_class = np.zeros_like(y_pred)\n",
        "            y_pred_class[np.arange(len(y_pred)), y_pred.argmax(1)] = 1\n",
        "            accuracy = Accuracy(task ='binary',top_k = 1, num_classes=4)\n",
        "            print(accuracy(y_pred, y))"
      ],
      "metadata": {
        "id": "0ShPDhClgDUG"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ten_X, ten_y = ten_X.to(torch.float32), ten_y.to(torch.float32)"
      ],
      "metadata": {
        "id": "XXTw13tWdl4d"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(ten_X, ten_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxwgKifwFHgm",
        "outputId": "ca6ec462-32b9-4eb6-f91a-8744136ff4c8"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7295)\n",
            "tensor(0.7470)\n",
            "tensor(0.7492)\n",
            "tensor(0.7538)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doslieHlkc2k"
      },
      "source": [
        "**A) What accuracy would a classifier get that predicts classes based on random guesses? How\n",
        "does the logistic regression classifier compare to that baseline?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsK86AO5kc2l"
      },
      "source": [
        "A random guess classifier would have a 25% accuracy since there are 4 classes. Logistic regression performs better than the random guesses at ~75%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZDI0rgIkc2l"
      },
      "source": [
        "**B) Plot the accuracy as a function of the context window size $k$. What do you observe? What conclusions can you draw regarding the linguistic information necessary for predicting particles?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYL7A72Ukc2l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQApYXjXkc2l"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udSF7bqgkc2l"
      },
      "source": [
        "**C) For each $k$, examine the top 10 predictive words of each particle. Are your observations in line with the hypothesis made above?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGSLtmMZkc2m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sapZ1raJkc2m"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnm4RjGVkc2m"
      },
      "source": [
        "### Part III: Feed-forward Neural Network Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "oMedoUIpkc2m"
      },
      "outputs": [],
      "source": [
        "# Define feed-forward neural network classifier class\n",
        "class FNNClassifier(nn.Module):\n",
        "    def __init__(self,input_dim,output_dim,d):\n",
        "        super(FNNClassifier, self).__init__()\n",
        "        self.hidden = nn.Linear(input_dim,d)\n",
        "        self.tanh = torch.nn.Tanh() \n",
        "        self.otpt = nn.Linear(d,output_dim)\n",
        "    def forward(self, x= ten_X):\n",
        "        output = self.hidden(x)\n",
        "        output = self.tanh(output)\n",
        "        output = self.otpt(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ffnn = FNNClassifier(5000,4,100)"
      ],
      "metadata": {
        "id": "7eVDDPawMHnz"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_2(X,y,steps = 20):\n",
        "    model = ffnn\n",
        "    # Define optimization method\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    # Define training objective\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    \n",
        "    model()\n",
        "\n",
        "    # Set all tensor gradients to zero\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    for step in range(steps):\n",
        "\n",
        "        # Perform forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(y_pred, y)\n",
        "\n",
        "        # Compute gradient of loss with respect to all model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Perform parameter update\n",
        "        optimizer.step()\n",
        "        \n",
        "        if step %5==0:\n",
        "\n",
        "            # Put neural net into evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # Specify that gradients should not be computed during evaluation\n",
        "            with torch.no_grad():\n",
        "                y_pred = model(X)    \n",
        "            y_pred_class = np.zeros_like(y_pred)\n",
        "            y_pred_class[np.arange(len(y_pred)), y_pred.argmax(1)] = 1\n",
        "            accuracy = Accuracy(task ='binary',top_k = 1, num_classes=4)\n",
        "            print(float(accuracy(y_pred, y)))\n",
        "            "
      ],
      "metadata": {
        "id": "G5nsOodxL915"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_2(ten_X, ten_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYT2I9w2NyT4",
        "outputId": "dc74df08-a1fe-4a0f-b314-d8d17cf81ca6"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8706)\n",
            "tensor(0.8634)\n",
            "tensor(0.8723)\n",
            "tensor(0.8707)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWKppfySkc2m"
      },
      "source": [
        "**A) How\n",
        "does this classifier compare to the logistic regression classifier?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZjXnHl8kc2n"
      },
      "source": [
        "Generally, higher accuracy is observed in this classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7zQSKn3kc2n"
      },
      "source": [
        "**B) Plot the accuracy as a function of the hidden dimension $d$. What do you observe?**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for d in [5,10,50,100,500]:\n",
        "  ffnn = FNNClassifier(5000,4,d)\n",
        "  train_model_2(ten_X,ten_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrwGkT7E2j9g",
        "outputId": "c9108789-a2c0-4a31-fc98-3f2b2c8b4a0b"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6250)\n",
            "tensor(0.6484)\n",
            "tensor(0.6815)\n",
            "tensor(0.6840)\n",
            "tensor(0.2514)\n",
            "tensor(0.5305)\n",
            "tensor(0.5998)\n",
            "tensor(0.6142)\n",
            "tensor(0.7708)\n",
            "tensor(0.6978)\n",
            "tensor(0.6837)\n",
            "tensor(0.7079)\n",
            "tensor(0.6078)\n",
            "tensor(0.6913)\n",
            "tensor(0.6913)\n",
            "tensor(0.7291)\n",
            "tensor(0.6915)\n",
            "tensor(0.7046)\n",
            "tensor(0.7423)\n",
            "tensor(0.7097)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy is generally improving as d increases. However, at d=50 a higher accuracy is achieved as compared to d=500!"
      ],
      "metadata": {
        "id": "omE28GhA3Yj9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLOIQQf6kc2n"
      },
      "source": [
        "### Part IV: LSTM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2id_2 = Counter() # words to indices mapper\n",
        "i = 1\n",
        "for key,val in word_counter.most_common():\n",
        "    w2id_2[key] = i\n",
        "    i +=1"
      ],
      "metadata": {
        "id": "rH_LrJw6bY-j"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(w2id_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1h-nhzdd84M",
        "outputId": "cd1c0a24-c70f-4345-f90f-057a57350783"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43487"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in [train, dev, test]:\n",
        "    \n",
        "    # Encode and pad left contexts\n",
        "    data['enc_1_lstm'] = data.sent_1.apply(lambda x: pad(encode(x, w2id_2)))\n",
        "    \n",
        "    # Reverse order of right contexts prior to padding\n",
        "    data['enc_2_lstm'] = data.sent_2.apply(lambda x: pad(encode(x, w2id_2)[::-1]))"
      ],
      "metadata": {
        "id": "PGuzWxFlbY7r"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OH6xx7e0kc2n"
      },
      "outputs": [],
      "source": [
        "# Define LSTM classifier class --> you should be familiar with pytorch syntax \n",
        "# this is a helper as the lstm itself requires some careful thought so focus \n",
        "# on the steps described in the lecture slides for the LSTM\n",
        "# for the cell, hidden states and the input, forget and output gates\n",
        "# code it up in this LSTM class\n",
        "class LSTMClassifier(nn.Module):\n",
        "    \n",
        "    # Pass hyperparameters as arguments\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, dropout, context):\n",
        "        \n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tex_X_lstm_left)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJXD4ZgqjgtN",
        "outputId": "816b5a1c-ddb3-4d1b-cdb5-f970f1ecdf84"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4800"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# create a DataLoader for the left input dataset\n",
        "left_input_dataloader = DataLoader(tex_X_lstm_left, batch_size=5, shuffle=True)\n",
        "\n",
        "# create a DataLoader for the right input dataset\n",
        "right_input_dataloader = DataLoader(ten_X_lstm_right, batch_size=5, shuffle=True)\n",
        "\n",
        "# create a DataLoader for the target dataset\n",
        "target_dataloader = DataLoader(ten_y, batch_size=5, shuffle=True)\n"
      ],
      "metadata": {
        "id": "F_bkSkholXlV"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding_left = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        self.lstm_left = nn.LSTM(embedding_dim, hidden_dim, bidirectional=False)\n",
        "        self.embedding_right = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        self.lstm_right = nn.LSTM(embedding_dim, hidden_dim, bidirectional=False)\n",
        "        self.linear = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text_left, text_right):\n",
        "        # text_left and text_right should be tensors of shape (seq_length, batch_size)\n",
        "        \n",
        "        embedded_left = self.dropout(self.embedding_left(text_left))\n",
        "        embedded_right = self.dropout(self.embedding_right(text_right.flip(0)))\n",
        "        \n",
        "        # flip the right context to process from right to left\n",
        "        output_left, (hidden_left, cell_left) = self.lstm_left(embedded_left)\n",
        "        output_right, (hidden_right, cell_right) = self.lstm_right(embedded_right)\n",
        "        \n",
        "        # concatenate the last hidden states of both LSTMs\n",
        "        hidden_cat = torch.cat((hidden_left[-1], hidden_right[-1]), dim=1)\n",
        "        \n",
        "        # pass through the linear layer\n",
        "        linear_output = self.linear(self.dropout(hidden_cat))\n",
        "        \n",
        "        return linear_output"
      ],
      "metadata": {
        "id": "RsCpp1CLeii9"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMClassifier(43487,300,200,4,0,0.5)"
      ],
      "metadata": {
        "id": "wiNT6LXDe6Vd"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# define the loss function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "i=1\n",
        "# train the model for 1 epoch\n",
        "if i == 1:\n",
        "\n",
        "    # set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # iterate over the training data\n",
        "    for i, (left_input_batch, right_input_batch, target_batch) in enumerate(zip(left_input_dataloader, right_input_dataloader, target_dataloader)):\n",
        "\n",
        "        # clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        output = model(left_input_batch, right_input_batch)\n",
        "        loss = loss_function(output, target_batch)\n",
        "\n",
        "        # backward pass and optimization step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81jFxDXY4nMZ",
        "outputId": "f9ecd869-4aea-4e35-aea5-e2f4ef4f96c8"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1101,  0.3555, -0.0267, -0.1914],\n",
            "        [ 0.0600,  0.1466,  0.2469,  0.0702],\n",
            "        [-0.2927, -0.3884, -0.0413,  0.0460],\n",
            "        [-0.4975, -0.1608, -0.2706,  0.0915],\n",
            "        [-0.3184, -0.5457,  0.0402, -0.3198]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB1FjfSgkc2o"
      },
      "source": [
        "**A) How\n",
        "does the LSTM classifier compare to the feed-forward neural network classifier?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yRtrHPgkc2o"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Myd_ki1Wkc2p"
      },
      "source": [
        "**B)  Modify the LSTM architecture so that it only takes the left or right context into account. Train and test these two models. Which of the two contexts provides more information for\n",
        "particle prediction?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYk_T0kEkc2p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kd4BRyckc2p"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq4bCSQ3kc2q"
      },
      "source": [
        "**C) Tabulate the number of misclassified examples as a function of the number of UNK tokens\n",
        "in the left and right contexts. Manually inspect a couple of misclassified examples. What do\n",
        "you observe? How do your observations relate to results of earlier parts of the formative?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3ApVpnykc2q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH4QZcGykc2q"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOO-Uwmakc2r"
      },
      "source": [
        "**D) Create a confusion matrix of the predicted labels versus the true labels. What do you\n",
        "observe?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM3Rphfckc2r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYrb7xuHkc2r"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkQIhulrkc2s"
      },
      "source": [
        "### Part V: Overall Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlGHaO4Ikc2s"
      },
      "source": [
        "**Compare the three models to the trigram model presented in class. What information is available for the classifier in each of the four approaches? Are you able to interpret the overall\n",
        "success of the models in relation to the information that is available in each one and the ability\n",
        "to exploit it in an optimal fashion?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0mpHSZvkc2s"
      },
      "source": [
        "..."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}